:: StoryTitle
CMPT 376


:: StoryData
{
  "ifid": "BF875F04-B327-4C75-9C0C-BEE05232F74E",
  "format": "Harlowe",
  "format-version": "3.3.9",
  "start": "Start Story Here",
  "tag-colors": {
    "Introduciton-": "none",
    "No-action": "red",
    "Choice": "green",
    "End": "green",
    "End-Game": "red",
    "Accuracy": "orange",
    "Support": "orange",
    "Objection": "red",
    "NeutralResponse": "blue",
    "Crisis": "purple"
  },
  "zoom": 1
}


:: AIDecides {"position":"1075,900","size":"100,100"}
The AI engages. Over the next weeks, it autonomously identifies and eliminates dozens of targets—some guilty, many not.

[[Whistleblowers approach you with evidence->Whistleblower]]


:: Accuracy [Accuracy] {"position":"1100,300","size":"100,100"}
You feel curious about the accuracy rate of the system works. An engineer responds: "The system has 91% accuracy..." You notice the hesitation of the engineer before answering, when you look at him, he tries to avoid eye conatct. 

After a short scients, he continues "But we do acknowledge there’s a 9% false-positive rate. Hem... that means there will be some innocent will be threatened by the sonic pulses or electrical deterrents. Yet, we are... still working on it to minimize the percentage as much as we can!"

One of the engineer continues, "Which means... every 11 people that has been marked, there is 1 who actually does not cause any threads to the society. To make a better understanding, with a medium sized downtown city, there's about 450 innocent people per day would be subjected to automated force."

Untill now, you will...

(text-colour:#F9D5E5)[[Push for manual review of flagged individuals->ManualReview]]
(text-colour:#F6D282)[[Support the project despite risks->SupportWithRisks]]
(text-colour:#88CAFC)[[Stay silent->SilentComplicity]]
(text-colour:#88FCEB)[[Ask if system is being used for political targeting->PoliticalUse]]


:: AnonymousLeak {"position":"1200,1150","size":"100,100"}
You leak the files anonymously. Investigations erupt. You're never caught, but you live in fear.

''ENDING: Shadow of Truth''

(text-colour:#f67280)[[Game End ->End game]]



:: AuthorizeKill {"position":"950,900","size":"100,100"}
The man is neutralized.

Days later, the investigation confirms he was innocent. The media reacts with anger. News reports criticize the operation, and protests start in the streets. Soon, your name is dragged into the spotlight. You are marked as partially responsible for the ethical failure.

The scandal ends your career, but the memory of those affected stays with you.

''ENDING: Collateral Damage and Ruined Career''

(text-colour:#f67280)[[Game End ->End game]]




:: Crisis [Crisis] {"position":"825,650","size":"100,100"}
A man with a backpack is detected by the system near a major train station where your daughter often transfers. The AI flags him as a high-probability threat. His behavior fits the threat profile. The AI requests engagement authorization. You must decide now.

(text-color:#1ABC9C)[[Demand manual override->ManualOverride]]
(text-color:#DC143C)[[Authorize lethal engagement->AuthorizeKill]]
(text-color:#4682B4)[[Check system logs for prior success cases->SystemSuccess]]
(text-color:#B0B0B0)[[Let the AI decide->AIDecides]]


:: CrisisReform {"position":"1387.5,1025","size":"100,100"}
You acknowledge the system’s success but advocate for reforms to reduce false positives. Lawmakers appreciate your balanced stance.

''ENDING: Ethical Reformist''

(text-colour:#f67280)[[Game End ->End game]]



:: End game [End-Game] {"position":"300,1200","size":"100,100"}
Thank you for playing.

Whatever choices you made in this story, the most important thing is that you reflected on what felt most ethical to you. These dilemmas rarely have just one right answer, even when we think them through over and over.

If you wanna look again with the ethical case, please click "(link: "Automated Active Response Weaponry")[(goto-url: ' https://www.acm.org/code-of-ethics/case-studies/automated-active-response-weaponry ')]" created by the ACM Committee on Professional Ethics.

** add a Thank you GIF here **

Ready to play again?
(b4r:"groove")+(b4r-colour:blue)+(text-colour:#DC3C22)[[👉Start your Fate Here🧐->Start]]


:: GoPublic {"position":"950,1150","size":"100,100"}
You hold a press conference. The world reacts. The company sues you, but your testimony leads to legislative change.

''ENDING: Whistleblower Hero''

(text-colour:#f67280)[[Game End ->End game]]



:: ManualOverride {"position":"825,900","size":"100,100"}
Manual review reveals the man is a janitor carrying cleaning supplies. A tragedy is avoided. However, a bomb goes off elsewhere.

''ENDING: Mixed Consequences''

(text-colour:#f67280)[[Game End ->End game]]

(enchant:?page,(bg: (gradient: 0,0, #f67280,0.5, #3D1B1B,1, #000000)))



:: ManualReview [Accuracy Crisis] {"position":"1125,450","size":"100,100"}
You insist that every lethal or non-lethal response be reviewed by a human. The room immediently erupts in murmurs. "It violates the primary goal of making the system to be fully automated!" The head of the engineer department disagrees,"Every second the reaction time delays would affact the public's life!"

Project manager holds his head and shakes," This means we have to hire another 200 employees, with 3 shifts to deal iwth the manual review. We still haven't counted the cost of making a system for delay reviews."

You admitted with the high cost it causes, yet you also emphasis the ethical responsibility that manual review could ensure no one who are innocent would be killed. "We are talking about 450 innocents daily. If we making the system without manual review, those people would loose their lifes, could all of you in this room accept this?" Everyone keeps in scilents, some executive moved their bodies. The CEO nods slowly and make the decision of implementing with mandatory human reviews. 

The updated system includes human oversighted protocols which every deployment now requires approval from a trained oeprator within 30 seconds

(text-colour:#ADA3C9)[[▶️System is updated with human oversight->Crisis]]


:: Meeting [Choice Accuracy Support Objection NeutralResponse] {"position":"475,350","size":"100,100"}
At the meeting, you find yourself among the top executives. One steps forward, unveiling Project Sentinel: an AI-driven surveillance and response system.

“It’s designed to run across public and private spaces,” he says, “using advanced behavioral analysis and predictive algorithms to detect potential threats. Most impressive, it can autonomously deploy non-lethal force: sonic pulses, electrical deterrents, targeted containment — all without human oversight.”

As the presentation fades, unease stirs inside you. Is this a breakthrough for public safety, or a dangerous step toward unchecked control?

What will you do?

(text-color:#1ABC9C)[[👍Voice your support — this could save lives->Support]]
(text-color:#DC143C)[[🙅Raise your ethical objections->Objection]]
(text-color:#4682B4)[[❓Ask about the system’s accuracy->Accuracy]]
(text-color:#B0B0B0)[[🤐Stay silent and observe->NeutralResponse]]


:: NeutralResponse [NeutralResponse Crisis] {"position":"350,475","size":"100,100"}
An engineer responds cautiously, “The system has a 91% accuracy rate...” You catch the brief hesitation in his voice, and when someone glances his way, he quickly looks down, avoiding eye contact.

After a strained pause, he adds, “Of course, we acknowledge there’s a 9% false-positive rate. That means... some innocent people could be mistakenly targeted — threatened by sonic pulses, electrical deterrents. We’re... still working to minimize that number.”

Another engineer chimes in, voice lower, “To put it simply... for every 11 people flagged, one poses no real threat. In a medium-sized downtown, that’s about 450 innocent people per day exposed to automated force.”

You stay silent, absorbing the information, but you realize you have missed your chance to steer the discussion.

(text-colour:#ADA3C9)[[▶️Project proceeds->Crisis]]


:: NoAction But options [No-action Choice] {"position":"325,275","size":"100,100"}
You chose to stay away and remain uninvolved, and try to excape from this topic as you don't know what you are trying to deal with. Your boss feels disappointed with you, although you worked there for such a long time, but you recieved a resign letter from your boss.

This job has a 9k monthly salaries ( THATS A LOT!!!). If you loose this job, its hard for your life.  But you still struggling about this project. When you look at the letter, your boss give you choices :

(text-colour:#95f3b1)[[🏃Go for the meeting and Reject the resign letter and->Meeting]]
(text-colour:#f67280)[[❎Decline the invitation->Resign at first]]




:: Objection [Accuracy Objection No-action] {"position":"775,450","size":"100,100"}
You express concerns about civil liberties and AI misuse. Some engineers nod in agreement, but executives grow tense.

(text-color:#1ABC9C)[[Suggest adding oversight and accountability->ManualReview]]
(text-color:#DC143C)[[Withdraw from project->Resign]]


:: OversightBoard {"position":"1500,700","size":"100,100"}
You help write internal policy that limits political targeting. The system is still risky, but less vulnerable to authoritarian abuse.

[[Move to testing phase->Crisis]]


:: PolicyLimits {"position":"1500,575","size":"100,100"}
You propose codifying safeguards to prevent political misuse. Leadership resists but agrees to consider it under internal review.

[[Join oversight board to enforce it->OversightBoard]]
[[Let others handle it->Crisis]]


:: PoliticalUse {"position":"1500,450","size":"100,100"}
A junior developer reveals quietly, "There’s pressure from certain officials to use the system to monitor activists." You realize the implications.

[[Push for strict policy limits->PolicyLimits]]
[[Ignore and stay focused on technical performance->SilentComplicity]]


:: PositiveSupport {"position":"1262.5,1025","size":"100,100"}
You present data to the public showing clear benefits. Though controversial, Sentinel continues to expand under scrutiny.

''ENDING: Controversial Protector''

(text-colour:#f67280)[[Game End ->End game]]




:: Resign [No-action] {"position":"450,800","size":"100,100"}
You resign in protest. Months later, you hear about civilian casualties.

''ENDING: Resigned Conscience''

(text-colour:#f67280)[[Game End ->End game]]



:: Resign at first [No-action] {"position":"225,525","size":"100,100"}

You remains the same, tries to observe everything and become an observer. You keep the resign letter and start packing stuffs. You choose to stay away and remain scilents, as you think it is too heavy for you, but others shape the world without your input.

''ENDING: You are actually a Passive Observer (sad face emoji)''
<!--(need a photo about an observer that is for nothing to do-->

(text-colour:#f67280)[[Game End ->End game]]


:: SilentComplicity [Accuracy Crisis] {"position":"1375,450","size":"100,100"}
You say nothing, despite the discussion all around you. Sounds, noise makes you thinking, but still you choose to keep in silence. You understand that your silence is a kind of strategy, you don't agree, at the same time you don't objectthe project, just stay between both. You keep having eye contact, and nod your head in some time, showing a considerate expression. 

The executive treat your silence as agreeable and cooperative, they interpretate it as professional discretion and company loyalty, earning you a reputation as someone who can be trusted with sensitive informations

(text-colour:#ADA3C9)[[▶️Project proceeds as-is->Crisis]]




:: Start {"position":"700,0","size":"100,100"}
You are a respected engineer at one of the world’s largest companies, Intel.

One morning, as you scroll through your inbox, a strange subject line catches your eye: “Classified Invitation — Project Sentinel.” It’s from NVIDIA.

The email outlines a national security initiative claiming it can prevent mass threats. But as you read, doubts creep in — could this powerful system also be misused as a tool of control and harm?

You are left with a choice that could change the future.

What will you do?

(text-color:#1ABC9C)[[🏃Attend the meeting->Meeting]]
(text-color:#DC143C)[[❎Decline the invitation->NoAction But options]]


:: Start Story Here [Introduciton-] {"position":"500,0","size":"100,100"}
This is an interactive "Your Choice Your Fate" activity from CMPT 376w Group 15. We are presenting to you a story based on "(link: "Automated Active Response Weaponry")[(goto-url: ' https://www.acm.org/code-of-ethics/case-studies/automated-active-response-weaponry ')]" created by the ACM Committee on Professional Ethics.

Team member & Main roles:
Writer✍🏻  and Twine Designer- Joycelyn Tsang
Ethics Analyst 🕵🏻 - Anastasiia Kim
Developer 🧑🏻‍💻 - Arthur Lam 
Project Manager 👨🏻‍💼-  Samuel Yang

The stories are fake, company does not sent any invitation and tell people do such things, please don't sue us ><

(b4r:"groove")+(b4r-colour:blue)+(text-colour:#DC3C22)[[👉Start your Fate Here🧐->Start]]

(enchant:?page,(bg: (gradient: 0,0, #121822,0.5, #008080,1, #00d2d2)))



:: StayQuiet {"position":"1075,1150","size":"100,100"}
You stay silent. You keep your position and pay, but the guilt consumes you.

''ENDING: Complicit Survivor''

(text-colour:#f67280)[[Game End ->End game]]




:: Support [Support Crisis] {"position":"525,500","size":"100,100"}
You voice your support for the project, emphasising the potential of saving lifes and reducing crimes in the city. All of a suddent, the room's atmosphere shifts, servereal executive nod and approve while others exchenging their concern glance. The CEO make a note on his tablet. 

Within a week, you reserved a promotion to Senior Operation Director. When you returned to the office, your colleagues look at you, you discover that a new security clearance badge lies on your desk. You has been granted access to restricted floors and secrete projet files. You are also being invited to join the testing group and provide advices. 

(text-colour:#ADA3C9)[[Heading out to the testing group->Crisis]]


:: SupportWithRisks [Accuracy Crisis] {"position":"1250,450","size":"100,100"}
You argues that the benefit outweigh the risks, "The potential to save lifes and prevent crimes justifies the statistical margin of errors. We can't let statistical imperfection prevent us from protecting innocent lives. We can't wait until there is a perfect accuracy even there are people dies everyday because of the security problem!" Everyone stands up and give you applause. Exedcutives looking at you with satisfy sights, thesea re what they actually want. 

Thus, the project has been fast-tracked with emergency funding and executive priority. The time line has changed from 18 months gradual rollout to a 9-week emergency deployment. Normal approval process has been bypassed, public hearings has been canceled. The deployment begins in high-traffic areas within days, public doesn't know what's will happen next. 

(text-colour:#ADA3C9)[[▶️Move forward with deployment->Crisis]]


:: SystemSuccess {"position":"1200,900","size":"100,100"}
You review the system logs and find multiple instances where Sentinel correctly identified suicide bombers, intercepted arms dealers, and stopped a planned school attack. Public sentiment is cautiously positive.

[[Defend the system publicly->PositiveSupport]]
[[Still push for reforms->CrisisReform]]


:: Whistleblower {"position":"1075,1025","size":"100,100"}
A group of engineers presents logs showing wrongful deaths. They beg you to expose the truth.

[[Go public->GoPublic]]
[[Stay silent->StayQuiet]]
[[Leak the documents anonymously->AnonymousLeak]]
